# AIXplore â€“ Team Workflow Library

> **Reusable AI-powered workflows for R&D teams â€“ parse clinical PDFs, extract structured insights, and validate outputs against source text.**

![Python](https://img.shields.io/badge/Python-3.12+-blue) ![FastAPI](https://img.shields.io/badge/FastAPI-0.114-009688) ![React](https://img.shields.io/badge/React-19-61DAFB) ![Azure OpenAI](https://img.shields.io/badge/Azure%20OpenAI-GPT--4o-orange) ![Azure Document Intelligence](https://img.shields.io/badge/Azure%20DI-prebuilt--layout-purple)

---

## Table of Contents

- [What is this?](#what-is-this)
- [Key Features](#key-features)
- [Architecture](#architecture)
- [Tech Stack](#tech-stack)
- [Project Structure](#project-structure)
- [Setup & Installation](#setup--installation)
- [Running the App](#running-the-app)
- [How It Works â€“ End to End](#how-it-works--end-to-end)
- [The Two Workflows](#the-two-workflows)
- [Grounding Validation & Self-Correction](#grounding-validation--self-correction)
- [Design Decisions & Trade-offs](#design-decisions--trade-offs)

---

## What is this?

**AIXplore** is a prototype for a _Team AI Infrastructure_ platform that lets R&D scientists create, share, and reuse AI-powered workflows. Instead of every team member writing one-off prompts, workflows are centralized: defined once, shared team-wide, and tracked for usage.

The prototype demonstrates this with **clinical/scientific paper analysis**: upload a PDF, pick a workflow, and get structured, validated JSON output â€” with every claim checked against the source text.

---

## Key Features

- ğŸ“„ **PDF Parsing** â€” Azure Document Intelligence (`prebuilt-layout`) extracts text, sections, tables, and span metadata
- ğŸ–¼ï¸ **Figure Extraction** â€” PyMuPDF extracts images from PDFs; GPT-4o vision describes each figure
- ğŸ§© **Section-Based Chunking** â€” Long papers split at DI-detected sections, processed in parallel, then synthesized
- ğŸ“‹ **Structured JSON Output** â€” LLM output constrained to a predefined JSON schema
- âœ… **Grounding Validation** â€” 3-layer system (stats matching + fuzzy quotes + LLM-as-judge) checks every claim
- ğŸ”„ **Self-Correction Loop** â€” Ungrounded claims sent back to GPT-4o for correction or removal
- ğŸ“ **Enriched Markdown Export** â€” Downloadable `.md` with inline tables and figure descriptions
- ğŸ“š **Workflow Library** â€” Browse, create, delete, and track usage of team workflows
- âš¡ **Parallel Processing** â€” 6 threads for vision, 4 for text chunks
- ğŸ’¾ **Figure Caching** â€” Vision results cached per document; subsequent runs skip expensive GPT-4o calls

---

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    React Frontend                    â”‚
â”‚   (Vite + TypeScript + Tailwind CSS, port 5173)      â”‚
â”‚                                                      â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚   â”‚ Library â”‚  â”‚   Run    â”‚  â”‚  Publish New    â”‚     â”‚
â”‚   â”‚  Page   â”‚  â”‚ Workflow â”‚  â”‚    Workflow     â”‚     â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚ REST API (axios)
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€-â”
â”‚                  FastAPI Backend                      â”‚
â”‚            (Python 3.12+, port 8000)                  â”‚
â”‚                                                       â”‚
â”‚  Routes:                                              â”‚
â”‚   POST /api/documents/parse    â†’ PDF parsing          â”‚
â”‚   GET  /api/workflows          â†’ list workflows       â”‚
â”‚   POST /api/runs               â†’ execute workflow     â”‚
â”‚   GET  /api/runs/{id}/download â†’ download JSON        â”‚
â”‚   GET  /api/runs/{id}/download-md â†’ download .md      â”‚
â”‚                                                       â”‚
â”‚  Services:                                            â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚  doc_intel  â”‚  â”‚   aoai     â”‚  â”‚  grounding   â”‚   â”‚
â”‚   â”‚  (DI + PyMu)â”‚  â”‚  (GPT-4o)  â”‚  â”‚  (3-layer)   â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚          â”‚               â”‚                â”‚           â”‚
â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚           â”‚
â”‚                  â–¼                        â”‚           â”‚
â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€-â”€â”                â”‚           â”‚
â”‚          â”‚workflow_runnerâ”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚          â”‚ (orchestrator)â”‚                            â”‚
â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€-â”˜                            â”‚
â”‚                                                       â”‚
â”‚  Storage: SQLite (aiosqlite) + file system            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€-â”€â”˜
                       â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â–¼            â–¼            â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€-â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Azure Doc   â”‚ â”‚  Azure  â”‚ â”‚   SQLite    â”‚
   â”‚ Intelligenceâ”‚ â”‚ OpenAI  â”‚ â”‚   + Files   â”‚
   â”‚ (parsing)   â”‚ â”‚ (GPT-4o)â”‚ â”‚   (local)   â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€-â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Tech Stack

### Backend

| Technology                  | Purpose                                      |
| --------------------------- | -------------------------------------------- |
| Python 3.12+                | Runtime                                      |
| FastAPI                     | Async REST API framework                     |
| aiosqlite                   | Async SQLite for workflows, runs, usage      |
| Azure Document Intelligence | PDF â†’ text, tables, sections, spans          |
| PyMuPDF (fitz)              | Native image extraction from PDFs            |
| Azure OpenAI (GPT-4o)       | Analysis, vision, grounding, self-correction |
| python-dotenv               | Environment variable management              |

### Frontend

| Technology     | Purpose                     |
| -------------- | --------------------------- |
| React 19       | UI framework                |
| TypeScript     | Type safety                 |
| Vite           | Fast dev server and bundler |
| Tailwind CSS 4 | Utility-first styling       |
| React Router 7 | Client-side routing         |
| Axios          | HTTP client                 |

---

## Project Structure

```
workflow_prototype/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py                  # FastAPI app, CORS, router mounting
â”‚   â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â”‚   â”œâ”€â”€ models.py            # SQLite connection helper
â”‚   â”‚   â”‚   â””â”€â”€ init_db.py           # Schema + seed workflows
â”‚   â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”‚   â”œâ”€â”€ documents.py         # POST /parse, GET /figure
â”‚   â”‚   â”‚   â”œâ”€â”€ workflows.py         # CRUD for workflows
â”‚   â”‚   â”‚   â””â”€â”€ runs.py              # POST /runs, download endpoints
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ doc_intel.py          # Azure DI + PyMuPDF image extraction
â”‚   â”‚   â”‚   â”œâ”€â”€ aoai.py               # GPT-4o calls: vision, chunking, synthesis
â”‚   â”‚   â”‚   â”œâ”€â”€ grounding.py          # 3-layer validation + self-correction
â”‚   â”‚   â”‚   â”œâ”€â”€ workflow_runner.py    # Orchestrator: vision â†’ LLM â†’ grounding
â”‚   â”‚   â”‚   â””â”€â”€ enriched_md.py        # Builds enriched markdown with tables/figures
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚       â””â”€â”€ json_safe.py          # JSON parsing helpers
â”‚   â”œâ”€â”€ data/                         # Runtime data (gitignored)
â”‚   â”‚   â”œâ”€â”€ app.db                    # SQLite database
â”‚   â”‚   â”œâ”€â”€ runs/                     # Saved run outputs (JSON + .md)
â”‚   â”‚   â”œâ”€â”€ parsed/                   # Parsed document text
â”‚   â”‚   â”œâ”€â”€ figures/                  # Extracted figure metadata
â”‚   â”‚   â””â”€â”€ figure_descriptions/      # Cached GPT-4o vision results
â”‚   â””â”€â”€ .env.example                  # Environment variable template
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ main.tsx                  # React entry point
â”‚   â”‚   â”œâ”€â”€ api/client.ts             # API functions (axios)
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”‚   â”œâ”€â”€ Library.tsx           # Team workflow library
â”‚   â”‚   â”‚   â”œâ”€â”€ RunWorkflow.tsx       # Upload + run workflow page
â”‚   â”‚   â”‚   â””â”€â”€ PublishWorkflow.tsx   # Create new workflows
â”‚   â”‚   â””â”€â”€ components/
â”‚   â”‚       â”œâ”€â”€ Layout.tsx            # App shell with navigation
â”‚   â”‚       â”œâ”€â”€ UploadPanel.tsx       # PDF upload + parse
â”‚   â”‚       â””â”€â”€ WorkflowOutput.tsx    # Results: triage/deep views, grounding
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ vite.config.ts
â”œâ”€â”€ sample_papers/                    # Example PDFs for demo
â”œâ”€â”€ requirements.txt                  # Python dependencies
â””â”€â”€ README.md                         # This file
```

---

## Setup & Installation

### Prerequisites

- **Python 3.12+** (conda or venv)
- **Node.js 18+** and npm
- **Azure subscription** with:
  - Azure Document Intelligence resource
  - Azure OpenAI resource with a **GPT-4o** deployment

### 1. Clone the repository

```bash
git clone https://github.com/<your-username>/workflow_prototype.git
cd workflow_prototype
```

### 2. Backend setup

```bash
# Create and activate a Python environment
conda create -n prototype python=3.13 -y
conda activate prototype

# Install dependencies
pip install -r requirements.txt
```

### 3. Configure environment variables

```bash
cp backend/.env.example backend/.env
```

Edit `backend/.env` with your Azure credentials:

```dotenv
# Azure Document Intelligence
AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT=https://your-resource.cognitiveservices.azure.com/
AZURE_DOCUMENT_INTELLIGENCE_KEY=your-key-here

# Azure OpenAI
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OPENAI_API_KEY=your-key-here
AZURE_OPENAI_MODEL_DEPLOYMENT=gpt-4o-deployment
AZURE_OPENAI_API_VERSION=2025-01-01-preview
```

### 4. Frontend setup

```bash
cd frontend
npm install
```

---

## Running the App

Open **two terminals**:

**Terminal 1 â€“ Backend** (from project root):

```bash
cd backend
uvicorn app.main:app --reload --port 8000
```

**Terminal 2 â€“ Frontend** (from project root):

```bash
cd frontend
npm run dev
```

Open [http://localhost:5173](http://localhost:5173) in your browser.

> The backend auto-creates the SQLite database and seeds two default workflows on first startup.

---

## How It Works â€“ End to End

Here's the full pipeline when a user uploads a PDF and runs a workflow:

### Step 1: PDF Parsing (`doc_intel.py`)

```
PDF upload â†’ Azure Document Intelligence (prebuilt-layout)
              â”‚
              â”œâ”€ Extracted text (full content)
              â”œâ”€ Sections (with headings and offsets)
              â”œâ”€ Tables (HTML rendering)
              â””â”€ Span metadata (for enriched markdown positioning)

         + PyMuPDF (fitz)
              â”‚
              â””â”€ Native image extraction
                  â”œâ”€ Filter: min 50Ã—50px, min 2KB, max aspect ratio 12
                  â”œâ”€ Deduplicate by xref ID
                  â””â”€ Output: base64-encoded images with page numbers
```

- **Azure Document Intelligence** provides structural understanding: headings, sections, tables with cell-level data.
- **PyMuPDF** extracts the actual embedded images (figures, charts, diagrams) directly from the PDF binary â€” more reliable than trying to identify figure regions from DI layout.
- Images are filtered to remove logos, icons, and decorative elements.

### Step 2: Figure Analysis (`aoai.py` â€” parallel vision)

```
Extracted images â†’ GPT-4o Vision (6 parallel threads)
                    â”‚
                    â”œâ”€ "NOT_A_FIGURE" â†’ filtered out (logos, headers)
                    â””â”€ Clinical description with:
                        â”œâ”€ Chart type identification
                        â”œâ”€ Key data points and trends
                        â”œâ”€ Statistical values from axes/labels
                        â””â”€ Clinical significance
```

- Each image is sent to GPT-4o with a specialized clinical vision prompt.
- GPT-4o identifies non-figure images (logos, decorative) and returns `NOT_A_FIGURE`.
- Descriptions are **cached per document** in `data/figure_descriptions/` â€” subsequent runs skip this expensive step.
- Figures are matched to paper references (Figure 1, Figure 2, etc.) using sequential pairing.

### Step 3: Structured Analysis (`aoai.py` â€” chunking + synthesis)

```
Paper text + figure descriptions â†’ Section-based chunking
                                     â”‚
                                     â”œâ”€ Chunk 1 (sections 1-3) â†’ GPT-4o â†’ partial JSON
                                     â”œâ”€ Chunk 2 (sections 4-6) â†’ GPT-4o â†’ partial JSON
                                     â””â”€ Chunk N (remaining)    â†’ GPT-4o â†’ partial JSON
                                                                    â”‚
                                                                    â–¼
                                                            Synthesis prompt
                                                            (merge all chunks)
                                                                    â”‚
                                                                    â–¼
                                                          Final structured JSON
```

- Long papers are split at DI-detected section boundaries (not arbitrary character counts).
- Small sections are merged until they hit a ~6000 character threshold.
- Each chunk is processed independently (4 parallel threads).
- A synthesis pass merges all partial outputs into a single JSON matching the workflow schema.
- Short papers (< threshold) skip chunking and go directly to GPT-4o.

### Step 4: Grounding Validation (`grounding.py`)

```
Structured JSON + source text â†’ 3-layer validation
                                  â”‚
                                  â”œâ”€ Layer 1: Value-based stat matching
                                  â”‚   â””â”€ Extract numbers, percentages, p-values,
                                  â”‚     CIs, HRs from both output and source,
                                  â”‚     then verify each stat appears in source
                                  â”‚
                                  â”œâ”€ Layer 2: Fuzzy quote verification
                                  â”‚   â””â”€ Check supporting_quotes against source
                                  â”‚     using token-level similarity (threshold: 0.60)
                                  â”‚
                                  â””â”€ Layer 3: LLM-as-judge
                                      â””â”€ GPT-4o reviews each claim and rates:
                                          âœ“ SUPPORTED â€“ clearly in source
                                          âš  PARTIAL  â€“ partially supported
                                          âœ— NOT_FOUND â€“ not grounded in source
```

### Step 5: Self-Correction (`grounding.py` + `workflow_runner.py`)

```
Ungrounded claims â†’ GPT-4o self-correction
                      â”‚
                      â”œâ”€ Corrected claims (rewritten with source evidence)
                      â””â”€ Removed claims (if no evidence exists)
                              â”‚
                              â–¼
                      Fast re-validation (regex + fuzzy only, no LLM)
                              â”‚
                              â–¼
                      Final grounding score with correction metadata
```

- If the grounding step finds errors, ungrounded claims are collected and sent back to GPT-4o.
- GPT-4o either **corrects** them (rewrites with proper source evidence) or **removes** them.
- The corrected output is re-validated using fast regex/fuzzy checks (skipping the LLM-as-judge to avoid latency).
- The UI shows correction metadata: what was changed, what was removed.

### Step 6: Output & Display

The frontend renders the validated output with:

- **Grounding banner**: overall score, claim counts (supported/partial/ungrounded), correction summary
- **Per-claim indicators**: inline âœ“/âš /âœ— icons with hover details
- **Extracted figures**: actual images from the PDF with GPT-4o descriptions
- **Download options**: structured JSON and enriched markdown

---

## The Two Workflows

### 1. Clinical Paper Triage (Quick)

**Purpose**: Fast screening â€” should this paper be read in depth?

**Output schema**:

- `tldr` â€” one-paragraph summary
- `key_findings` â€” bullet points
- `biomarkers` â€” genes, proteins, lab measures
- `trial_phase_signals` â€” Phase I/II/III/Preclinical/Unknown
- `patient_population` â€” who was studied
- `follow_up_hypotheses` â€” next experiments to run
- `supporting_quotes` â€” 3-6 source quotes
- `confidence` â€” low/medium/high

**Processing**: Single-pass, no figure analysis, no chunking for short papers.

### 2. Deep Paper Analysis (Comprehensive)

**Purpose**: Full extraction with visual elements, statistical evidence, and safety data.

**Output schema**:

- `paper_metadata` â€” title, authors, journal, DOI
- `study_design` â€” type, methodology, sample size, duration
- `tldr` â€” summary
- `key_findings` â€” each with `finding`, `statistical_evidence`, `clinical_significance`
- `biomarkers_and_endpoints` â€” name, type, result
- `figures_and_tables_summary` â€” reference, description, key data
- `safety_profile` â€” adverse events, SAEs, discontinuation rate
- `limitations`, `clinical_implications`, `follow_up_hypotheses`
- `supporting_quotes` â€” 4-8 source quotes
- `confidence` â€” low/medium/high

**Processing**: Full pipeline with figure vision, section-based chunking, parallel processing.

---

## Grounding Validation & Self-Correction

This is the most technically interesting part. LLMs hallucinate. In pharma R&D, a hallucinated statistic could lead to wrong decisions. The grounding system ensures **every claim maps back to the source text**.

### Why 3 layers?

| Layer                 | Catches                                           | Speed   |
| --------------------- | ------------------------------------------------- | ------- |
| **Value-based stats** | Wrong numbers, fabricated p-values                | âš¡ Fast |
| **Fuzzy quotes**      | Paraphrased or fabricated quotes                  | âš¡ Fast |
| **LLM-as-judge**      | Subtle misinterpretations, unsupported inferences | ğŸ¢ Slow |

- **Stats matching** extracts numbers/percentages/p-values from the output and searches for them in the source text
- **Fuzzy matching** checks supporting quotes against the source using token-level similarity (â‰¥ 60%)
- **LLM judge** has GPT-4o cross-reference each claim against the source and rate it SUPPORTED / PARTIAL / NOT_FOUND

Each layer catches different failure modes. Stats matching is cheap and catches the most dangerous errors (wrong numbers). Fuzzy matching verifies quotes. The LLM judge catches nuanced errors that regex can't.

### Self-correction in action

```
Before correction:                    After correction:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
"HR = 0.72 (95% CI 0.58-0.89)"     "HR = 0.64 (95% CI 0.58-0.71)"
  âœ— NOT_FOUND â€“ stat not in source    âœ“ SUPPORTED â€“ corrected to source value

"Survival improved by 40%"           [REMOVED â€“ no evidence in source]
  âœ— NOT_FOUND â€“ percentage fabricated
```

---

## Design Decisions & Trade-offs

- **SQLite over PostgreSQL** â€” Prototype scope: zero setup, single-file DB, sufficient for demo
- **File-system caching** â€” Figure descriptions cached as JSON per document; simple, inspectable, no invalidation complexity
- **PyMuPDF over DI figures** â€” DI's figure detection was unreliable for clinical charts; PyMuPDF extracts actual embedded images
- **Sequential figure matching** â€” When image count = figure ref count, Figure N = Nth image in page order (simpler & more accurate)
- **Section-based chunking** â€” Splitting at DI-detected sections preserves context better than arbitrary character splits
- **Skip LLM on re-validation** â€” After self-correction, re-validate with regex/fuzzy only; avoids a second expensive GPT-4o call
- **Temperature 0.2** â€” Low temperature for structured extraction reduces randomness, improves consistency
- **Single correction round** â€” Diminishing returns after 1 round; keeps latency manageable

---

## Demo Walkthrough

1. **Open the app** â†’ Library page shows two pre-seeded workflows with descriptions and run counts
2. **Click "Run this workflow â†’"** â†’ Navigate to Run Workflow page
3. **Upload a clinical PDF** â†’ Document Intelligence parses it; you see page count and text preview
4. **Click "Run Workflow"** â†’ Watch the pipeline execute:
   - Figure extraction + GPT-4o vision
   - Section-based LLM analysis
   - Grounding validation + self-correction
5. **View results** â†’ Structured output with grounding banner, per-claim indicators, and extracted figures
6. **Download** â†’ Get the structured JSON or enriched markdown

---

## License

This is a prototype built for assessment purposes.
